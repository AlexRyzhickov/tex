\subsection*{Review 3}

This paper seems to show that programs can be constructed that perform better using one algorithm (for MiniKanren) than another (ECCE for Prolog).  As mentioned on page 2, "there are no ways to predict the effect of specialization on a given program in general".  So it is hard to see what general conclusions can be drawn from this empirical study.

Many parts of the paper are written clearly but overall, more clarification of the purpose and significance of the experiment is needed.

\emph{In this paper we demonstrated some issues which arise in \mk specialization and proposed an approach to deal with them. The proposed algorithm does not yet demonstrate the degree of specialization we strive for. We still consider it a step towards our goal. }

This paper reminds me of some of the discussions about control of partial evaluation of logic programs in the 1990s.  It seems that some of these issues are being rediscovered in the context of MiniKanren, for example the handling of deterministic choices.  See for example Section 4 of [2].

MiniKanren and Prolog are similar languages, as shown by the experiments in which programs are translated from one language to the other.  However they have differences in their execution strategy and the translation could affect the execution.  This is a vital aspect that needs to be addressed.  Each language implementation is optimised for its respective execution strategy.

\emph{Since the languages are similar, it was natural to try solutions for specialization which already exist first. Hence we run the experiments and discovered that CPD did not solve our problem. If CPD worked as well for \mk as we expected, we would just apply it and move on to the next challenge.}

However, all the experimental results seem to be achieved by running the programs as MiniKanren programs.  I.e. a Prolog program extracted from ECCE is executed as a MiniKanren program!

This seriously detracts from the value of the experiment. I think that the experiments should go both ways; i.e. run all the programs both as Prolog and as MiniKanren.

\emph{Although running \mk relations as \pro programs is a nice experiment on its own, it does not advance us to the goal of running relational interpreters backwards efficiently, thus we did not do it.}

Detailed comments.

page 1. impelement $\Rightarrow$ implement

page 2.  ``What is worse, the efficiency of residual program from the target language evaluator point of view is rarely considered in the literature.'' This is certainly not true of PE for Prolog.  See for example references [1], [2].

\emph{We did not say it had never been considered.}

page 3.  While it is true that CPD (ECCE) optimises programs for a left-to-right strategy. CPD can unfold any atom in a conjunction.  This preserves its logical semantics.  It is not true to state that CPD only ``unfolds atoms from left to right''.

\emph{We realize that CPD can use different unfolding strategies. We were referring to the settings which proved to be the most beneficial in~\cite{leuschel1997advanced}.}

page 3.  The strategy for CPD provided by ECCE can be varied, as mentioned.  However, the experiments apparently only use the default settings.

\emph{This is true.}

page 3. ``The strategy of unfolding atoms from left to right is reasonable in the context of PROLOG because it mimics the way programs in PROLOG execute. But it often leads to larger global control trees and, as a result, bigger, less efficient programs.''  This is misleading, possible false.  Unfolding the leftmost atoms can clearly NEVER increase the size of the search space when executing left to right.  It merely pushes forward some choices (which often can improve indexing in the head clause and improve performance). So what is meant by ``larger global trees'' and ``less efficient programs''. Please provide a clear example.

However, unfolding non-deterministic non-leftmost atoms CAN increase the search space of a left-right execution, since goals to the left of the unfolded atom are duplicated.

\emph{All this was mentioned in the context of \mk, not \pro, where the execution strategy is not left to right.}


page 3. A feature of CPD that seems to be ignored is that a conjunction can be unfolded, i.e. it is not always ``atom-by-atom'' but a conjunction p,q can be treated as a single predicate pq.  This allows more powerful specialisations, loop fusion, etc.  It is not clear whether MiniKanren can achieve these specialisations.

\emph{We realize CPD treats conjunctions as a single predicate. Conservative partial deduction does exactly that too: once a conjunction is encountered which is a renaming of another conjunction, we do not proceed to split it or unfold any of the relation calls within it. We note that it is a renaming and residualize it into a new predicate in the same manner CPD does.}


page 4.  Note that putting formulas in canonical form (disjunction of conjunctions) blows up the size of the program and can also increase the search.  This is a critical part of the experiment that needs to be addressed.  It would be better to define a new predicate for each construct, and then interpret it.  E.g.

\verb!p :- s,(q \/ r).!

should be translated as

\verb!p :- s,qr.!

\verb!qr :- q.!

\verb!qr :- r.!

rather than

\verb!p :- s,q.!

\verb!p :- s,r.!

Executing the second form repeats execution of s, but the first form does not.  If the normalize function uses the second form, it casts serious doubt about the whole experiment.

\emph{This is an important comment, thank you. Normalization does deteriorate the performance of programs in the exact cases you described. However the experiments we discuss in the paper do not get affected: the original versions of the programs are in normal form from the beginning.}

page 5.  The mechanism of generalisation seems very crude.  It might work for the given examples but seems too simple to be used in general.  More powerful generalisation using abstract interpretation and related methods have been widely studied.

\emph{The decision to generalize only by splitting was made in pursuit of lowering the algorithm's complexity and in attempt to single out the effects our specialization method has on the program. It is not hard to integrate more intricate generalization. This is left for future work. }

page 6.  Please explain more clearly why the two problems were chosen. It is stated that they are examples of relational interpreters to solve search problems. This is a special kind of program - can the results be expected to apply to other programs?

\emph{The goal of our project is to improve backwards execution of relational interpreters (see section~\ref{relinterp} for context). We chose these two programs as examples to demonstrate the common issues faced when dealing with automatically generated relational interpreters. The examples are meant to be small and observable, so the reader can fully comprehend them.}

\emph{The issues are not specific for interpreters: any program may have relation calls which restrict substitutions considerably, but are not placed leftmost within a conjunctions. Also, one of the best pratices in programming is to not write the same code twice, thus many relations use calls to other relations in their definitions. Multiple unfoldings are often needed to get usefull results in such a case. Thus we believe our approach will apply to other kinds of relational programs. }

page 9, Fig 3.  It should be made absolutely clear whether the programs are all run in MiniKanren (not Prolog). In my opinion this casts doubt on the validity of the experiments, since ECCE is designed to optimised execution for Prolog.

\emph{We added the explanation in the first paragraph of section~\ref{evaluation}}


[1] Raf Venken, Bart Demoen:
A Partial Evaluation System for Prolog: some Practical Considerations. New Gener. Comput. 6(2\&3): 279-290 (1988)

[2] J.P. Gallagher: Tutorial on Logic Program Specialisation"  (PEPM 1993).